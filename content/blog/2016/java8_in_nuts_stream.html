---
title: "java8 in a Nutshell--Stream API"
created: !!timestamp '2016-1-21 23:20:00'
image: /media/images/blog/2016/streams.png
tags:
- Java
---

{% block excerpt %}
{% mark excerpt %}
Stream are the key abstraction in Java8 for processing collections of value.
Streams follow the "what,not how" priciple,you don't need to specify how to get the data.
you just specify how the computation should work.
{% endmark %}
{% endblock %}

# Stream Creation
for collection,you can call <b>stream(or parallStream)</b> method to create a stream
{% syntax Java %}
List<String> words =...
long count = words.stream().filter((s) -> s.length()>2).count();
{% endsyntax %}
or create with <b>Stream.of</b> method
{% syntax Java %}
Stream<String> stream = Stream.of("A,B,C".split(","));
Stream<String> stream = Stream.of("A","B","C");
Stream<String> empty = Stream.empty(); // empty Stream
{% endsyntax %}
and you can also create a infinite stream using <b>generate</b> method
{% syntax Java %}
Stream.generate(Supplier<T> s);
//for example
Stream<Double> randoms = Stream.generate(Math::random)
{% endsyntax %}

#filter,map,flatMap
all these methods are transformation operations,these operations will read data from stream
and put transferred data into another stream(stream operation will not mutate the original data.)
{% syntax Java %}
/\*\*
\* Returns a stream consisting of the elements of this stream that match
\* the given predicate.
\*
\* <p>This is an <a href="package-summary.html#StreamOps">intermediate
\* operation</a>.
\*
\* @param predicate a <a href="package-summary.html#NonInterference">non-interfering</a>,
\*                  <a href="package-summary.html#Statelessness">stateless</a>
\*                  predicate to apply to each element to determine if it
\*                  should be included
\* @return the new stream
\*/
Stream<T> filter(Predicate<? super T> predicate);


/\*\*
\* Returns a stream consisting of the results of applying the given
\* function to the elements of this stream.
\*
\* <p>This is an <a href="package-summary.html#StreamOps">intermediate
\* operation</a>.
\*
\* @param <R> The element type of the new stream
\* @param mapper a <a href="package-summary.html#NonInterference">non-interfering</a>,
\*               <a href="package-summary.html#Statelessness">stateless</a>
\*               function to apply to each element
\* @return the new stream
\*/
<R> Stream<R> map(Function<? super T, ? extends R> mapper);


/\*\*
\* Returns a stream consisting of the results of replacing each element of
\* this stream with the contents of a mapped stream produced by applying
\* the provided mapping function to each element.  Each mapped stream is
\* {@link java.util.stream.BaseStream#close() closed} after its contents
\* have been placed into this stream.  (If a mapped stream is {@code null}
\* an empty stream is used, instead.)
\*
\* <p>This is an <a href="package-summary.html#StreamOps">intermediate
\* operation</a>.
\*
\* @apiNote
\* The {@code flatMap()} operation has the effect of applying a one-to-many
\* transformation to the elements of the stream, and then flattening the
\* resulting elements into a new stream.
\*
\* <p><b>Examples.</b>
\*
\* <p>If {@code orders} is a stream of purchase orders, and each purchase
\* order contains a collection of line items, then the following produces a
\* stream containing all the line items in all the orders:
\* <pre>{@code
\*     orders.flatMap(order -> order.getLineItems().stream())...
\* }</pre>
\*
\* <p>If {@code path} is the path to a file, then the following produces a
\* stream of the {@code words} contained in that file:
\* <pre>{@code
\*     Stream<String> lines = Files.lines(path, StandardCharsets.UTF_8);
\*     Stream<String> words = lines.flatMap(line -> Stream.of(line.split(" +")));
\* }</pre>
\* The {@code mapper} function passed to {@code flatMap} splits a line,
\* using a simple regular expression, into an array of words, and then
\* creates a stream of words from that array.
\*
\* @param <R> The element type of the new stream
\* @param mapper a <a href="package-summary.html#NonInterference">non-interfering</a>,
\*               <a href="package-summary.html#Statelessness">stateless</a>
\*               function to apply to each element which produces a stream
\*               of new values
\* @return the new stream
\*/
<R> Stream<R> flatMap(Function<? super T, ? extends Stream<? extends R>> mapper);
{% endsyntax %}

lets see some examples about these methods ,suppose we have Developer as VO.
a Developer have name,and can use several languages.
{% syntax Java %}
class Developer {

private String name;
private Set<String> languages;

public Developer(String name) {
this.languages = new HashSet<>();
this.name = name;
}
public String getName(){
return this.name;
}
public void add(String language) {
this.languages.add(language);
}

public Set<String> getLanguages() {
return languages;
}
}

{% endsyntax %}

and suppose now we have a list of Developers
{% syntax Java %}
List<Developer> developers = DeveloperService.getAllDevelopers();
{% endsyntax %}

and you want print every developer name whose name start with "Peter"
{% syntax Java %}
developers.stream().map((d)-> d.getName() ).filter((name) -> name.startWith("Peter")).forEach(System.out::println) ;
// the map method will generate a new stream which consist of developer names
// and then invoke filter on that stream , and check if name start with "Peter" , if exists, it will put another new Stream
//Finally print every name in the new Stream
{% endsyntax %}
Now suppose you want all set languages of all the developers
{% syntax Java %}
developers.stream.map((d)->d.getLanguages()).forEach(System.out::println)
{% endsyntax%}
But this will end up print some list like below output
{% syntax Java %}
[groovy, scala, clojure, go]
[java, javascript]
{% endsyntax %}
but what if I just want one total list of languages, for this requirement,you can use flatMap
{% syntax Java %}
developers.stream().
map(d -> d.getLanguages())
.flatMap(l -> l.stream())
.forEach(System.out::println);
{% endsyntax %}
now you can get result like below
{% syntax Java %}
groovy
scala
clojure
go
java
javascript
{% endsyntax %}

#Extracting SubStream and Combining Streams
`stream.limit(n)` returns a new stream that ends after n elements.
{% syntax Java %}
Stream<Double> tenStream = Stream.generate(Math::random).limit(10) // tenStream only have 10 elements
{% endsyntax %}
`stream.skip(n)` does the opposite, it discards the first n elements
{% syntax Java %}
Stream twoStream = Stream.of("A","B","C").skip(1)  // twoStream only have B and C
{% endsyntax %}
`Stream.concat(stream1,stream2)` can concat two stream as one.

#Basic Reduction
Now we have already created and transform streams , now we need get the most important part:
get the result of the stream. to get a result from a stream,you need to call a reduction 
method(terminal operation),these methods reduce a value of your stream that you can use in you programe.

`count` method return the number of elements in the stream
{% syntax Java %}
Stream<String> stream = Stream.of("A","B","C","A");
long count = stream.filter((s) -> s.equals("A")).count(); // count should be 2
{% endsyntax %}

`max` and `min` returns the max value and min value of the stream.
{% syntax Java %}
Stream<String> stream = Stream.of("A","B","C","A");
Optional<String> max = stream.map(s -> s.toLowerCase()).max(String::compareToIgnoreCase); // return Optional[c]
if (max.isPresent()) {
	System.out.println(max.get());
}
{% endsyntax %}

`findFrist` return the first value in the nonEmpty collection
`findAny` find any match in filter , will be effective when use parallStream
`anyMatch` will return true if there's a match in the stream , it takes a Predicate as a param

{% syntax Java %}
Stream<String> stream = Stream.of("ABC","BCD","CD","AXY");

Optional<String> first =  stream.filter(s -> s.startsWith("A")).findFirst();
if (first.isPresent()){
  System.out.println(first.get());
}
stream = Stream.of("ABC","BCD","CD","AXY"); // if not assgin again, will throw Exception since the stream already close in above terminal operation(findFirst)
Optional<String> any =  stream.parallel().filter(s->s.startsWith("A")).findAny();
if (any.isPresent()){
    System.out.println(any.get());
}
stream = Stream.of("ABC","BCD","CD","AXY");
boolean anyMatch = stream.filter(s->s.endsWith("D")).anyMatch(s->s.equals("CD"));
System.out.println(anyMatch);
{% endsyntax %}

now lets take a look at `Optional` type.
{% syntax Java %}
Optional<String> first =  stream.filter(s -> s.startsWith("A")).findFirst();

first.ifPresent(System.out::println) // takes a consumer as a input
or 
first.orElse("")		// if empty stream, will be ""
or
first.orElseGet(()->System.getProperty("user.dir")) // if empty stream, will be user.dir value
you can even throw Exception when there is no value
first.orElseThrow(NoSUchElementException::new)
{% endsyntax %}

if you want to use `Optional` , please use `Optional.empty()` , and `Optional.of()`

#Reduction operation
if you want combine the elements of the stream in another way , you need write 
`reduce` method , the simplest form takes a binaryFunction and keeps apply it , start with first two
{% syntax Java %}
Stream<Integer> intStream = Stream.of(1,2,3);
Optional<Integer> op = intStream.reduce((x,y)->x+y); // this equals v1+v2+v3
{% endsyntax %}

in general , if the `reduce` method have reduction operation `op` ,the reduction should yields
v0 `op` v1 `op` v2... 

often,there is an identity e such that e `op` x = x , and so you can use e as the start of the computation, for example , 0 is the identity of add ,1 is identity of multiply
 {% syntax Java %}
Stream<Integer> intStream = Stream.of(1,2,3);
Integer op = intStream.reduce(0,(x,y)->x+y); // since ,at least it will be 0, so the result is Integer instead of Optional<Integer>
 {% endsyntax %}

#Collecting result
you may want to get the result of the stream instead of reduce it to a value.
for that , you can just call `iterator` method which will return a iterator that you can 
used to visit the elements.Or you can just call `toArray` to generate an array of stream elements
there are a convenient `Collector` interface to collect stream to `List` or `Set`
{% syntax Java %}
Stream<String> stream = Stream.of("1","2","3");
String[] arr =  stream.toArray(String[]::new); // you can not run below code at the same time
List list = stream.collect(Collectors.toList());
Set<String> set = stream.collect(Collectors.toSet());
String result = stream.collect(Collectors.joining()); // concat the String
 IntSummaryStatistics intSummaryStatistics =  stream.collect(Collectors.summarizingInt(Integer::valueOf));
int max = intSummaryStatistics.getMax(); 
{% endsyntax %}
you can even collect to a map, its very convenient.
{% syntax Java %}
Map<Integer, String> idToName = people.collect( Collectors.toMap(Person::getId, Person::getName)); //key is id,and value is name;
Map<Integer, Person> idToPerson = people.collect( Collectors.toMap(Person::getId, Function.identity()));//key is id , and the value is the element itself.
{% endsyntax %}
If there are more than one element with the same key, you will get `IllegalStateException`
but you can override the default behaviour by providing the third function argument
{% syntax Java %}
Stream<Locale> locales = Stream.of(Locale.getAvailableLocales()); 
locales.collect(Collectors.toMap(
	l->l.getDisplayCountry(),
	l->Collections.singleton(l.getDisplayLaunguage()),
	(a,b) -> {
		Set<String> r = new HashSet<>(a);
		r.addAll(b);
		return r;
	}
	)) // this will return the map  which the key is country_code and the value is the set of languages

{% endsyntax %}

#Grouping and Partitioning
to make it convenient to form the group of values , you can use `groupingBy` method
{% syntax Java %}
class Student{
        private String name ;

        private String course;

        Student(String name, String course) {
            this.name = name;
            this.course = course;
        }

        public String getName() {
            return name;
        }

        @Override
        public String toString() {
            return "Student{" +
                    "name='" + name + '\'' +
                    ", course='" + course + '\'' +
                    '}';
        }
    }


Stream<Student> studentStream = Stream.of(new Student("Peter","Math"),
        new Student("Peter","Computer"),
        new Student("Peter","English"),
        new Student("Angel","Math"),
        new Student("Angel","English")
        ,new Student("AI","Chinese"),
        new Student("AI","Math"));

 Map<String,List<Student>> studentMap = studentStream.collect(Collectors.groupingBy(s -> s.getName()));
 // will return a map , which group by name (key is name , value will be list of  the element itself).
{% endsyntax %}

you can also use other collectors in `groupingBy` method
{% syntax Java %}
 /\*\*
     \* Returns a {@code Collector} implementing a cascaded "group by" operation
     \* on input elements of type {@code T}, grouping elements according to a
     \* classification function, and then performing a reduction operation on
     \* the values associated with a given key using the specified downstream
     \* {@code Collector}.
     \*
     \* <p>The classification function maps elements to some key type {@code K}.
     \* The downstream collector operates on elements of type {@code T} and
     \* produces a result of type {@code D}. The resulting collector produces a
     \* {@code Map<K, D>}.
     \*
     \* <p>There are no guarantees on the type, mutability,
     \* serializability, or thread-safety of the {@code Map} returned.
     \*
     \* <p>For example, to compute the set of last names of people in each city:
     \* <pre>{@code
     \*     Map<City, Set<String>> namesByCity
     \*         = people.stream().collect(groupingBy(Person::getCity,
     \*                                              mapping(Person::getLastName, toSet())));
     \* }</pre>
     \*
     \* @implNote
     \* The returned {@code Collector} is not concurrent.  For parallel stream
     \* pipelines, the {@code combiner} function operates by merging the keys
     \* from one map into another, which can be an expensive operation.  If
     \* preservation of the order in which elements are presented to the downstream
     \* collector is not required, using {@link #groupingByConcurrent(Function, Collector)}
     \* may offer better parallel performance.
     \*
     \* @param <T> the type of the input elements
     \* @param <K> the type of the keys
     \* @param <A> the intermediate accumulation type of the downstream collector
     \* @param <D> the result type of the downstream reduction
     \* @param classifier a classifier function mapping input elements to keys
     \* @param downstream a {@code Collector} implementing the downstream reduction
     \* @return a {@code Collector} implementing the cascaded group-by operation
     \* @see #groupingBy(Function)
     \*
     \* @see #groupingBy(Function, Supplier, Collector)
     \* @see #groupingByConcurrent(Function, Collector)
     \*/
    public static <T, K, A, D>
    Collector<T, ?, Map<K, D>> groupingBy(Function<? super T, ? extends K> classifier,
                                          Collector<? super T, A, D> downstream) {
        return groupingBy(classifier, HashMap::new, downstream);
    }
{% endsyntax %}

#Parallel Streams
By default , the stream operation is sequential, you can get parallel stream by calling 
`parallelStream` in collection or `parallel` to convert a sequential stream to a parallel stream 
if a stream operation run in parallel, and you expect the same result should be returned as if 
they are run serially, its important to make sure that the operations is <em>stateless</em>
and can be executed in any order.

and its your responsibility to ensure that any function run in parallel stream is `thread-safe`.

By default , the stream is ordered, sometimes ,you don't intrested in order, you can call
`Stream.unordered`




                {# Local Variables: #}
{# mode: markdown #}
{# End: #}